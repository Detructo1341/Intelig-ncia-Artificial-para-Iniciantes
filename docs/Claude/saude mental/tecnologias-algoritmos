# Tecnologias e Algoritmos: Fundamentos Técnicos

Detalhamento técnico das principais tecnologias de IA aplicadas em saúde mental, com foco em "como funciona" para profissionais da área.

---

## 1. Processamento de Linguagem Natural (NLP)

### 1.1 Análise de Sentimento

**O que é:** Classificar texto em categorias emocionais (positivo/negativo/neutro ou emoções específicas).

**Abordagens:**

**Método 1: Léxico-baseado (Simples)**
- Lista de palavras com scores emocionais
- Exemplo:
  - "feliz" = +2
  - "triste" = -2
  - "deprimido" = -3
- Soma scores de todas palavras no texto
- **Vantagem:** Rápido, interpretável
- **Limitação:** Ignora contexto ("não estou feliz" = positivo?!)

**Método 2: Machine Learning Supervisionado**
- Treina modelo com textos rotulados
- Features: bag-of-words, TF-IDF, n-gramas
- Algoritmo: Naive Bayes, SVM, Random Forest
- **Vantagem:** Captura contexto melhor que léxico
- **Limitação:** Precisa de muitos dados rotulados

**Método 3: Deep Learning (Atual padrão)**
- Redes neurais (LSTM, Transformer)
- Aprende representações complexas automaticamente
- Exemplo: BERT fine-tuned para sentimento
- **Vantagem:** Estado-da-arte em acurácia
- **Limitação:** Requer muitos dados e computação

**Aplicação em saúde mental:**
```python
# Pseudocódigo
texto = "Não aguento mais essa ansiedade constante"

# Análise multi-nível
sentimento_geral = modelo.prever_sentimento(texto)  
# → Negativo (95%)

emocao_especifica = modelo.prever_emocao(texto)  
# → Ansiedade (80%), Desesperança (60%)

intensidade = modelo.prever_intensidade(texto)  
# → Alta (8/10)

urgencia = modelo.avaliar_urgencia(texto)  
# → Moderada (requer follow-up, não emergência)
```

### 1.2 Detecção de Distorções Cognitivas

**Desafio:** Identificar padrões de pensamento distorcidos (catastrofização, pensamento dicotômico, etc.).

**Abordagem baseada em regras:**
- Palavras-chave: "sempre", "nunca", "tudo", "nada" → pensamento dicotômico
- Padrões: "vai ser terrível", "desastre" → catastrofização
- Limitação: Falsos positivos ("sempre quis visitar Paris")

**Abordagem com ML:**
- Dataset: Milhares de pensamentos rotulados com distorções
- Features: 
  - Palavras absolutas (frequência)
  - Estrutura sintática (negações, condicionais)
  - Contexto emocional
- Modelo: Classificador multi-label (pensamento pode ter múltiplas distorções)

**Exemplo real - Sistema de TCC automatizado:**
```
Input: "Se eu errar essa apresentação, minha carreira acabou"

Análise de distorções:
- Catastrofização: 90% (palavra "acabou" é extrema)
- Pensamento dicotômico: 70% ("errar" implica só sucesso ou fracasso total)
- Previsão de futuro: 85% ("carreira acabou" = conclusão não-baseada em fatos)

Output sugerido (para chatbot):
"Noto alguns padrões de pensamento que podem estar intensificando sua ansiedade:
1. Catastrofização: 'carreira acabou' é o pior cenário possível, mas quão provável é realmente?
2. Pensamento tudo-ou-nada: E se não for erro total ou sucesso total? E se for 'ok'?

Vamos examinar as evidências?"
```

### 1.3 Análise de Coerência (Psicose)

**Objetivo:** Detectar desorganização de pensamento característica de esquizofrenia.

**Métricas computacionais:**
- **Coerência semântica:** Quão relacionadas são frases consecutivas?
- **Tangencialidade:** Desvio frequente do tópico principal?
- **Densidade de ideias:** Quantidade de conceitos únicos por frase

**Técnica: Semantic Coherence Score**
1. Converter frases em embeddings (vetores numéricos)
2. Calcular similaridade cosseno entre frases consecutivas
3. Média de similaridade = coerência do texto

```python
frases = [
    "Eu gosto de pizza",
    "Pizza é um prato italiano",
    "A Itália fica na Europa"
]
# Coerência alta: cada frase relaciona-se à anterior

frases_desorganizadas = [
    "Eu gosto de pizza",
    "O céu é azul",
    "Meu irmão mora longe"
]
# Coerência baixa: "saltos" entre tópicos não-relacionados
```

**Validação clínica:**
- Estudos mostram: pacientes com esquizofrenia têm coerência 30-40% menor que controles
- Pode detectar surto 2-3 dias antes de sintomas óbvios (análise de mensagens de texto)

---

## 2. Machine Learning para Predição

### 2.1 Classificação Binária: Deprimido vs. Não-Deprimido

**Pipeline típico:**

**Passo 1: Coleta de dados**
- Features (variáveis):
  - Demográficas: idade, gênero
  - Clínicas: histórico, comorbidades
  - Comportamentais: sono, atividade física, uso de smartphone
  - Linguísticas: sentimento em textos, tempo de resposta

**Passo 2: Pré-processamento**
- Imputação de dados faltantes (substituir por média ou prever)
- Normalização (escalar todas features para mesma escala)
- Codificação de categóricas (one-hot encoding)

**Passo 3: Seleção de features**
- Identificar quais features mais importam
- Técnicas: LASSO, Random Forest feature importance
- Remove redundância (sono ruim e sonolência diurna são correlacionados)

**Passo 4: Treinamento**
- Split: 70% treino, 15% validação, 15% teste
- Algoritmos comuns:
  - **Logistic Regression:** Simples, interpretável
  - **Random Forest:** Robusto, lida bem com dados desbalanceados
  - **Gradient Boosting (XGBoost):** Frequentemente melhor performance
  - **Redes Neurais:** Para datasets muito grandes

**Passo 5: Avaliação**
- Métricas:
  - **Acurácia:** % de predições corretas (cuidado: enganosa se classes desbalanceadas)
  - **Sensibilidade (Recall):** % de deprimidos detectados (crítico em saúde - não queremos perder casos)
  - **Especificidade:** % de não-deprimidos corretamente classificados
  - **AUC-ROC:** Área sob curva (0.5 = acaso, 1.0 = perfeito)

**Trade-off sensibilidade vs. especificidade:**
- Alta sensibilidade (detectar todos deprimidos) → mais falsos positivos (não-deprimidos classificados como deprimidos)
- Alta especificidade (não alarmar não-deprimidos) → mais falsos negativos (perder casos reais)
- Em saúde mental: preferimos alta sensibilidade (melhor falso positivo que falso negativo)

**Exemplo de resultado:**
```
Modelo XGBoost para depressão:
- Acurácia: 78%
- Sensibilidade: 85% (de 100 deprimidos, detecta 85)
- Especificidade: 75% (de 100 não-deprimidos, classifica 75 corretamente)
- AUC: 0.82 (bom)

Features mais importantes:
1. Padrões de sono (insônia/hipersonia)
2. Anedonia (perda de prazer) score
3. Histórico familiar de depressão
4. Isolamento social (↓ frequência de contatos)
5. Lentidão psicomotora (via tempo de digitação)
```

### 2.2 Regressão: Predição de Scores Contínuos

**Exemplo: Prever PHQ-9 (0-27) baseado em dados de smartphone**

Features coletadas passivamente:
- Tempo de tela
- Uso de apps (sociais, entretenimento, produtividade)
- Padrões de movimento (GPS)
- Chamadas/mensagens (frequência, duração)
- Dados de wearable (sono, FC, HRV)

Algoritmo: Gradient Boosting Regression

Performance:
- R² = 0.65 (explica 65% da variância)
- MAE (Erro Absoluto Médio) = 3.2 pontos
- Clínica: Predição dentro de 3 pontos do real é útil para monitoramento

**Aplicação:**
- Monitorar pacientes entre consultas
- Alertar se score predito sobe >5 pontos (piora significativa)

### 2.3 Time Series Analysis: Predição de Trajetória

**Objetivo:** Prever como sintomas evoluirão ao longo do tempo.

**Técnicas:**

**ARIMA (AutoRegressive Integrated Moving Average)**
- Modelo clássico para séries temporais
- Captura tendências e sazonalidade
- Aplicação: Prever humor nas próximas 2 semanas baseado em histórico de 3 meses

**LSTM (Long Short-Term Memory)**
- Rede neural recorrente especializada em sequências
- "Memória" de longo prazo para capturar padrões distantes
- Aplicação: Prever risco de recaída baseado em histórico completo de sintomas

**Exemplo - Predição de Recaída Depressiva:**
```python
# Input: Séries temporais de 6 meses
dados = {
    'humor_diario': [6, 5, 6, 7, 6, 5, 4, 3, 2, 3, ...],  # 180 dias
    'sono_horas': [7, 6.5, 7, 8, 7, 6, 5, 4, 4, 5, ...],
    'atividade_social': [5, 4, 5, 6, 5, 4, 3, 2, 1, 1, ...]
}

# Modelo LSTM treinado com 1000+ pacientes
predicao = modelo_lstm.prever(dados)

# Output:
# Probabilidade de recaída nas próximas 4 semanas: 72%
# Padrão detectado: Declínio gradual em humor + sono + atividade social
# Recomendação: Agendar sessão terapêutica preventiva
```

---

## 3. Deep Learning e Redes Neurais

### 3.1 Redes Convolucionais (CNN) - Análise de Imagem

**Aplicação: Detecção de Emoções via Expressão Facial**

Arquitetura:
1. **Input:** Imagem facial (224x224 pixels)
2. **Camadas convolucionais:** Detectam features (bordas, formas, texturas)
3. **Pooling:** Reduz dimensionalidade, mantém informação essencial
4. **Fully connected layers:** Classifica emoção

Emoções detectadas: Felicidade, Tristeza, Raiva, Medo, Surpresa, Nojo, Neutro

**Uso clínico:**
- Análise de vídeos de sessões terapêuticas
- Detectar incongruência: paciente diz "estou bem" mas expressão mostra tristeza
- Monitoramento de pacientes deprimidos (↓ expressividade facial = "flat affect")

**Limitações:**
- Variação cultural (expressões têm significados diferentes)
- Máscaras emocionais (paciente suprime expressão voluntariamente)

### 3.2 Redes Recorrentes (RNN/LSTM) - Análise de Sequências

**Aplicação: Análise de Fala para Detecção de Depressão**

Features acústicas extraídas:
- **Pitch (tom):** ↓ pitch em depressão
- **Variação de pitch:** ↓ variação (monotonia)
- **Velocidade de fala:** ↓ velocidade (lentidão psicomotora)
- **Pausas:** ↑ duração e frequência de pausas
- **Energia:** ↓ energia vocal (volume baixo)

Pipeline:
1. Gravar 2 minutos de fala (leitura de texto padrão ou conversa livre)
2. Extrair features acústicas frame-a-frame (cada 25ms)
3. LSTM processa sequência de features
4. Classifica: deprimido vs. não-deprimido

Performance:
- Acurácia: 80-85% (comparável a avaliação clínica breve)
- Vantagem: Objetivo, não depende de auto-relato

**Estudo real - IBM Watson + Partners Healthcare:**
- Analisou 1000+ ligações para clínica psiquiátrica
- Detectou depressão com 82% acurácia apenas pela voz
- Implementação: Triagem automática de pacientes em fila de espera

### 3.3 Transformers - Modelos de Linguagem (LLMs)

**Como funcionam (simplificado):**

**Mecanismo de Atenção:**
- Cada palavra "pergunta": quais outras palavras são relevantes para entender meu significado?
- Exemplo: "O gato comeu o rato. Ele estava com fome."
  - "Ele" presta atenção em "gato" (90%) e "rato" (10%)
  - Modelo entende que "ele" = gato

**Pré-treinamento:**
- Modelo lê bilhões de textos
- Tarefa: Prever próxima palavra
- Aprende gramática, fatos, padrões linguísticos

**Fine-tuning para saúde mental:**
- Treino adicional com:
  - Protocolos de TCC
  - Transcrições terapêuticas (anonimizadas)
  - Literatura científica de psicologia
  - Conversas de linhas de apoio emocional

**Exemplo - GPT fine-tuned para contexto terapêutico:**
```
Input: "Estou me sentindo muito ansioso hoje"

GPT genérico:
"Sinto muito. Ansiedade pode ser difícil. Quer conversar sobre isso?"

GPT fine-tuned:
"Entendo que você está ansioso. Para te ajudar melhor:
1. Em que situações a ansiedade surge mais?
2. O que você sente no corpo quando fica ansioso?
3. Que pensamentos passam pela sua cabeça nesses momentos?

Baseado no que você me contar, posso sugerir técnicas específicas de TCC ou respiração."
```

**Diferença:** Fine-tuning torna respostas mais alinhadas com práticas baseadas em evidências.

---

## 4. Análise de Dados Fisiológicos

### 4.1 Heart Rate Variability (HRV)

**O que é:** Variação no intervalo entre batimentos cardíacos.

**Por que importa:** HRV reflete atividade do sistema nervoso autônomo:
- Alta HRV = boa regulação emocional, resiliência ao estresse
- Baixa HRV = estresse crônico, ansiedade, depressão

**Medição:**
- Wearables (Apple Watch, Fitbit, Oura Ring)
- Intervalos R-R em ECG
- Medidas: RMSSD (raiz quadrada média das diferenças sucessivas)

**Aplicação em saúde mental:**
```python
# Análise de HRV ao longo de 4 semanas
dados_hrv = {
    'semana_1': {'RMSSD_media': 45, 'min': 30, 'max': 60},
    'semana_2': {'RMSSD_media': 40, 'min': 25, 'max': 55},
    'semana_3': {'RMSSD_media': 32, 'min': 20, 'max': 45},  # ↓ Queda
    'semana_4': {'RMSSD_media': 28, 'min': 18, 'max': 40}   # ↓ Continua caindo
}

# IA detecta: Declínio consistente em HRV
# Interpretação: Sistema de estresse cronicamente ativado
# Alerta: Risco aumentado de episódio depressivo/ansioso
# Recomendação: Intervenção preventiva (mindfulness, exercício, check-in terapêutico)
```

### 4.2 Padrões de Sono

**Dados coletados (via wearable ou smartphone):**
- Latência de sono (tempo para adormecer)
- Duração total
- Despertares noturnos (frequência e duração)
- Fases de sono (REM, sono leve, sono profundo)

**Biomarcadores de transtornos:**
- **Depressão:** Insônia inicial ou terminal, ↑ REM early (primeiras horas)
- **Mania:** ↓↓ sono (3-4h/noite) sem cansaço percebido
- **Ansiedade:** Dificuldade para adormecer (mente acelerada), sono fragmentado
- **PTSD:** Pesadelos (detectáveis por ↑ FC e movimento durante REM)

**Algoritmo de detecção:**
```python
def analise_sono(dados_30_dias):
    # Extrai features
    latencia_media = mean(dados['latencia'])
    despertares_media = mean(dados['despertares'])
    duracao_media = mean(dados['duracao'])
    variabilidade = std(dados['duracao'])  # Consistência
    
    # Padrões de transtornos
    if latencia_media > 30 and duracao_media < 6:
        return "Padrão consistente com ansiedade ou depressão"
    elif duracao_media < 5 and variabilidade > 2:
        return "Padrão errático, investigar mania ou uso de substâncias"
    elif despertares_media > 5:
        return "Sono fragmentado, investigar ansiedade ou PTSD"
    else:
        return "Padrão de sono dentro do normal"
```

### 4.3 Análise de Movimento (Acelerômetro)

**Features extraídas:**
- Distância total percorrida por dia
- Tempo sedentário vs. ativo
- Regularidade de rotina (acordar/dormir mesma hora)
- Velocidade de movimento (lentidão psicomotora)

**Marcadores de depressão:**
- ↓ Movimento total (isolamento, apatia)
- ↑ Tempo em casa (evitação social)
- ↓ Velocidade de caminhada (lentidão psicomotora)
- Irregularidade de rotina (sono desregulado)

**Estudo validação:**
- 60 pacientes com depressão + 60 controles
- Acelerômetro por 2 semanas
- Modelo ML detectou depressão com 75% acurácia baseado APENAS em padrões de movimento

---

## 5. Técnicas de Integração Multimodal

**Desafio:** Combinar múltiplos tipos de dados (texto, voz, movimento, fisiologia) para avaliação holística.

**Abordagens:**

**Early Fusion:** Combinar features antes de modelo
```python
features_combinadas = [
    sentimento_texto,
    features_voz,
    hrv_media,
    distancia_caminhada
]
modelo.treinar(features_combinadas, rotulo_depressao)
```

**Late Fusion:** Modelos separados, combinar predições
```python
pred_texto = modelo_nlp.prever(texto)  # 70% deprimido
pred_voz = modelo_audio.prever(voz)     # 80% deprimido
pred_movimento = modelo_accel.prever(movimento)  # 60% deprimido

# Ensemble (média ponderada)
predicao_final = 0.4*pred_texto + 0.4*pred_voz + 0.2*pred_movimento
# = 72% deprimido
```

**Multimodal Deep Learning:**
- Rede neural com múltiplos "braços" (um para cada modalidade)
- Camadas finais integram informação de todos braços
- Aprende automaticamente como ponderar cada modalidade

**Performance típica:**
- Unimodal (só texto): 75% acurácia
- Multimodal (texto+voz+movimento): 85% acurácia
- Ganho de 10% justifica complexidade adicional

---

## 6. Explicabilidade e Interpretabilidade

**Problema:** Modelos complexos (deep learning) são "caixas pretas".

**Técnicas de XAI (Explainable AI):**

**SHAP (SHapley Additive exPlanations):**
- Atribui "importância" a cada feature para predição específica
- Exemplo:
  ```
  Paciente X classificado como 85% deprimido
  
  Contribuições:
  + Sono < 6h/noite: +30%
  + Sentimento negativo em textos: +25%
  + Isolamento social: +20%
  + HRV baixo: +10%
  
  Fatores protetores:
  - Exercício regular: -5%
  - Apoio familiar relatado: -5%
  ```

**LIME (Local Interpretable Model-agnostic Explanations):**
- Cria modelo simples (linear) que aproxima modelo complexo localmente
- Identifica quais palavras em texto influenciaram predição

**Attention Weights (para Transformers):**
- Visualiza quais palavras o modelo "prestou atenção"
- Exemplo: Em "Não aguento mais", modelo focou em "não aguento" (risco)

**Importância para clínica:**
- Terapeuta precisa entender "por quê" para confiar
- Paciente tem direito de saber base da classificação
- Auditoria e detecção de viés

---

## 7. Infraestrutura e Deployment

### 7.1 Onde Rodar IA

**Cloud (AWS, Google Cloud, Azure):**
- Vantagem: Escalável, manutenção gerenciada
- Desvantagem: Privacidade (dados saem do dispositivo)

**Edge (no dispositivo - smartphone, wearable):**
- Vantagem: Privacidade preservada, funciona offline
- Desvantagem: Limitação de poder computacional

**Híbrido:**
- Features sensíveis processadas localmente
- Predições enviadas para cloud (sem dados brutos)

### 7.2 Monitoramento de Modelos em Produção

**Data Drift:** Distribuição de dados muda ao longo do tempo
- Exemplo: Modelo treinado pré-pandemia pode falhar pós-pandemia (contextos diferentes)
- Solução: Retreinamento periódico

**Model Decay:** Performance degrada com tempo
- Monitoramento contínuo de acurácia
- Alarme se cai abaixo de threshold

---

## Conclusão Técnica

**Estado atual (2025):**
- NLP e ML supervisionado: Maduros, deployable
- Deep learning multimodal: Emergente, alguns casos de uso
- IA Generativa (LLMs): Experimentação ativa, regulamentação pendente

**Próximos 3-5 anos:**
- Personalização será norma
- Modelos multimodais integrados
- Edge computing para privacidade
- Explicabilidade mandatória

**Competências essenciais para psicólogos:**
- Não precisa programar, mas entender conceitos (precisão, recall, overfitting)
- Questionar resultados ("por que modelo decidiu isso?")
- Colaborar com cientistas de dados com perspectiva clínica

---

Para aplicações práticas, ver: `aplicacoes_clinicas.md` e `casos_praticos.md`
Para questões éticas, ver: `etica_limitacoes.md`
