# Agentes de IA: Guia Prático

Referência baseada nos guias oficiais da Anthropic sobre construção de agentes efetivos e engenharia de contexto.

## Índice
1. [O Que São Agentes](#o-que-são-agentes)
2. [Quando Usar Agentes](#quando-usar-agentes)
3. [Blocos de Construção](#blocos-de-construção)
4. [Padrões de Workflow](#padrões-de-workflow)
5. [Agentes Autônomos](#agentes-autônomos)
6. [Engenharia de Contexto](#engenharia-de-contexto)
7. [Tarefas de Longo Prazo](#tarefas-de-longo-prazo)
8. [Melhores Práticas](#melhores-práticas)

---

## O Que São Agentes

A Anthropic categoriza sistemas agênticos em duas arquiteturas distintas:

### Workflows
Sistemas onde LLMs e ferramentas são orquestrados através de caminhos de código pré-definidos. Oferecem previsibilidade e consistência para tarefas bem-definidas.

### Agentes
Sistemas onde LLMs direcionam dinamicamente seus próprios processos e uso de ferramentas, mantendo controle sobre como realizam tarefas. Ideais quando flexibilidade e tomada de decisão guiada pelo modelo são necessárias em escala.

**Definição simples de agente:** LLMs usando ferramentas autonomamente em um loop.

---

## Quando Usar Agentes

### Princípio Fundamental
**Encontre a solução mais simples possível** e só aumente a complexidade quando necessário.

### Quando NÃO usar agentes
- Quando uma única chamada de LLM com retrieval e exemplos é suficiente
- Para tarefas simples e bem-definidas
- Quando previsibilidade total é crítica

### Quando usar agentes
- ✅ Problemas abertos onde é difícil prever o número de passos necessários
- ✅ Quando não é possível codificar um caminho fixo
- ✅ Para escalar tarefas em ambientes confiáveis
- ✅ Quando você tem algum nível de confiança na tomada de decisão do modelo

### Trade-offs
Agentes frequentemente trocam **latência e custo** por **melhor performance na tarefa**:
- Maior custo por operação
- Potencial para erros compostos
- Requer testes extensivos em ambientes sandbox
- Necessita guardrails apropriados

---

## Blocos de Construção

### LLM Aumentado
Bloco fundamental de sistemas agênticos: um LLM aprimorado com:

**Retrieval:** Busca de informações externas
**Ferramentas (Tools):** Capacidade de executar ações
**Memória:** Retenção de informações relevantes

**Implementação recomendada:**
- Model Context Protocol (MCP) para integração com ferramentas de terceiros
- Interface bem documentada e fácil de usar
- Ferramentas adaptadas ao caso de uso específico

---

## Padrões de Workflow

### 1. Prompt Chaining (Encadeamento)
Decompõe tarefa em sequência de passos onde cada chamada de LLM processa a saída da anterior.

**Quando usar:**
- Tarefa pode ser decomposta em subtarefas fixas
- Trade-off de latência por maior precisão

**Exemplos:**
- Gerar copy de marketing → traduzir para outro idioma
- Escrever outline → verificar critérios → escrever documento

**Estrutura:**
```
Entrada → LLM 1 → Gate/Verificação → LLM 2 → Gate → LLM 3 → Saída
```

---

### 2. Routing (Roteamento)
Classifica entrada e direciona para tarefa especializada de follow-up.

**Quando usar:**
- Categorias distintas que são melhor tratadas separadamente
- Classificação pode ser feita com precisão

**Exemplos:**
- Queries de atendimento ao cliente → processos específicos (reembolso, suporte técnico, geral)
- Perguntas fáceis → Haiku 4.5 (eficiente) / Perguntas difíceis → Sonnet 4.5 (capaz)

**Estrutura:**
```
Entrada → Classificador → Rota A / Rota B / Rota C
```

---

### 3. Parallelization (Paralelização)
LLMs trabalham simultaneamente em uma tarefa com outputs agregados programaticamente.

**Duas variações:**

**Sectioning (Setorização):** Quebrar tarefa em subtarefas independentes executadas em paralelo
- Guardrails: um modelo processa queries, outro verifica conteúdo inapropriado
- Avaliações automatizadas: cada LLM avalia aspecto diferente

**Voting (Votação):** Executar mesma tarefa múltiplas vezes para obter outputs diversos
- Revisar código para vulnerabilidades com múltiplos prompts
- Avaliar conteúdo inapropriado com diferentes perspectivas

**Quando usar:**
- Subtarefas podem ser paralelizadas para velocidade
- Múltiplas perspectivas necessárias para maior confiança
- Considerações complexas (LLMs performam melhor quando cada aspecto é tratado separadamente)

**Estrutura:**
```
Entrada → [LLM 1 | LLM 2 | LLM 3] → Agregação → Saída
```

---

### 4. Orchestrator-Workers (Orquestrador-Trabalhadores)
LLM central quebra tarefas dinamicamente, delega a LLMs trabalhadores e sintetiza resultados.

**Quando usar:**
- Tarefas complexas onde não é possível prever subtarefas necessárias
- Diferença-chave da paralelização: subtarefas não são pré-definidas, mas determinadas pelo orquestrador

**Exemplos:**
- Produtos de codificação com mudanças complexas em múltiplos arquivos
- Tarefas de busca que reúnem e analisam informações de múltiplas fontes

**Estrutura:**
```
Entrada → Orquestrador → [Worker 1 | Worker 2 | Worker N] → Síntese → Saída
```

---

### 5. Evaluator-Optimizer (Avaliador-Otimizador)
Uma chamada de LLM gera resposta enquanto outra fornece avaliação e feedback em loop.

**Quando usar:**
- Critérios de avaliação claros
- Refinamento iterativo fornece valor mensurável
- Respostas podem ser demonstravelmente melhoradas com feedback articulado
- LLM consegue fornecer esse feedback

**Sinais de bom fit:**
1. Respostas de LLM melhoram quando humano articula feedback
2. LLM consegue fornecer esse tipo de feedback

**Exemplos:**
- Tradução literária com nuances que podem ser criticadas
- Tarefas de busca complexas requerendo múltiplas rodadas

**Analogia:** Processo iterativo de escrita de um escritor humano ao produzir documento polido.

**Estrutura:**
```
Entrada → Generator → Evaluator → [Feedback Loop] → Saída Final
```

---

## Agentes Autônomos

### Características Essenciais
Agentes estão emergindo em produção conforme LLMs amadurecem em capacidades-chave:
- Compreender inputs complexos
- Raciocínio e planejamento
- Usar ferramentas confiavelmente
- Recuperar-se de erros

### Fluxo de Trabalho

**1. Início:**
- Comando ou discussão interativa com usuário
- Esclarecer tarefa

**2. Execução Independente:**
- Planejar e operar autonomamente
- Obter "verdade fundamental" (ground truth) do ambiente a cada passo
- Tool call results ou execução de código para avaliar progresso

**3. Checkpoints Humanos:**
- Pausar para feedback em checkpoints
- Pausar ao encontrar bloqueios
- Retornar ao humano para mais informações ou julgamento

**4. Terminação:**
- Conclusão da tarefa
- Condições de parada (ex: número máximo de iterações)

### Implementação
Geralmente são apenas **LLMs usando ferramentas baseado em feedback ambiental em loop**.

**Crucial:** Design de toolsets e documentação clara e cuidadosa.

### Exemplos de Uso (Anthropic)
- Agente de coding para resolver tarefas SWE-bench (edições em múltiplos arquivos)
- "Computer use" - Claude usando computador para realizar tarefas

---

## Engenharia de Contexto

### O Que É Context Engineering

**Contexto:** Conjunto de tokens incluídos ao amostrar de um LLM.

**Prompt Engineering:** Métodos para escrever e organizar instruções de LLM.

**Context Engineering:** Conjunto de estratégias para **curar e manter o conjunto ótimo de tokens** durante inferência de LLM, incluindo todas as outras informações além dos prompts.

### Por Que É Importante

**Context Rot (Degradação de Contexto):**
Conforme o número de tokens na janela de contexto aumenta, a habilidade do modelo de relembrar informações com precisão **diminui**.

**Analogia:** Como humanos têm capacidade limitada de memória de trabalho, LLMs têm um "orçamento de atenção" que consomem ao processar grandes volumes de contexto.

### Restrições Arquiteturais

**Transformer Architecture:**
- Cada token atende a todos os outros tokens em todo o contexto
- Resulta em n² relações par-a-par para n tokens
- Conforme comprimento do contexto aumenta, capacidade de capturar relações fica esticada

**Distribuição de Treinamento:**
- Modelos têm menos experiência com sequências longas
- Menos parâmetros especializados para dependências context-wide
- Resulta em gradiente de performance (não cliff abrupto)

### Princípio Orientador
**Encontre o menor conjunto possível de tokens de alto sinal que maximize a probabilidade do resultado desejado.**

---

## Anatomia de Contexto Efetivo

### System Prompts

**Altitude certa:**
- ❌ **Muito baixo:** Lógica complexa e frágil codificada (rigidez, difícil manutenção)
- ❌ **Muito alto:** Orientação vaga e high-level (falta sinais concretos, assume contexto compartilhado falsamente)
- ✅ **Goldilocks Zone:** Específico o suficiente para guiar comportamento, flexível o suficiente para fornecer heurísticas fortes

**Organização:**
- Seções distintas: `<background_information>`, `<instructions>`, Tool guidance, Output description
- XML tagging ou Markdown headers
- Formatação exata se tornando menos importante conforme modelos melhoram

**Objetivo:** Conjunto mínimo de informação que delineia completamente comportamento esperado (mínimo ≠ curto).

**Estratégia:**
1. Começar com prompt mínimo no melhor modelo disponível
2. Testar performance na tarefa
3. Adicionar instruções claras e exemplos baseado em failure modes

---

### Tools (Ferramentas)

**Eficiência dupla:**
1. Retornar informação token-efficient
2. Encorajar comportamentos eficientes do agente

**Características de boas ferramentas:**
- Auto-contidas
- Robustas a erros
- Extremamente claras quanto ao uso pretendido
- Parâmetros de input descritivos e não-ambíguos
- Minimal overlap em funcionalidade
- Jogam com forças inerentes do modelo

**Failure mode comum:**
Toolsets inchados que cobrem muita funcionalidade ou levam a pontos de decisão ambíguos.

**Regra:** Se um engenheiro humano não consegue dizer definitivamente qual ferramenta usar, um agente de IA também não conseguirá.

---

### Examples (Exemplos)

**Few-shot prompting:** Best practice bem conhecida e fortemente recomendada.

**❌ Não recomendado:**
- Encher prompt com lista de edge cases tentando articular cada regra possível

**✅ Recomendado:**
- Curar conjunto de exemplos diversos e canônicos
- Exemplos que efetivamente retratam comportamento esperado do agente

**Princípio:** Para um LLM, exemplos são as "imagens" que valem mil palavras.

---

## Retrieval de Contexto e Busca Agêntica

### Mudança de Paradigma

**Antes:** Embedding-based retrieval em pre-inference time para surfacear contexto importante.

**Agora:** Estratégias de contexto "just in time".

### Abordagem "Just in Time"

**Ao invés de:**
- Pre-processar todos dados relevantes antecipadamente

**Agentes:**
- Mantêm identificadores leves (file paths, queries armazenadas, web links)
- Usam ferramentas para carregar dados dinamicamente em runtime

**Exemplo (Claude Code):**
- Escreve queries direcionadas
- Armazena resultados
- Usa comandos Bash (head, tail) para analisar grandes volumes
- Nunca carrega objetos de dados completos no contexto

**Analogia:** Cognição humana - não memorizamos corpus inteiros, mas introduzimos sistemas externos de organização e indexação (file systems, inboxes, bookmarks).

---

### Benefícios do Metadata

**Sinais de contexto:**
- `test_utils.py` em pasta `tests/` implica propósito diferente de mesmo nome em `src/core_logic/`
- Hierarquias de pasta
- Convenções de nomenclatura
- Timestamps

Todos fornecem sinais que ajudam humanos e agentes a entender como/quando utilizar informação.

---

### Progressive Disclosure

**Descoberta incremental:** Agentes descobrem contexto relevante através de exploração.

Cada interação rende contexto que informa próxima decisão:
- Tamanhos de arquivo sugerem complexidade
- Convenções de nomenclatura sugerem propósito
- Timestamps são proxy para relevância

**Agentes montam compreensão camada por camada:**
- Mantêm apenas o necessário em working memory
- Usam estratégias de note-taking para persistência adicional
- Janela de contexto auto-gerenciada focada em subconjuntos relevantes

---

### Trade-offs

**Vantagem:** Eficiência de contexto

**Desvantagem:** Exploração em runtime é mais lenta que retrieval pré-computado

**Requer:**
- Engenharia opinativa e cuidadosa
- Ferramentas certas e heurísticas para navegar landscape de informação efetivamente
- Sem orientação adequada: agente pode desperdiçar contexto, perseguir dead-ends, falhar em identificar informação-chave

---

### Estratégia Híbrida

**Combinação:** Retrieval de alguns dados antecipadamente (velocidade) + exploração autônoma (flexibilidade)

**Exemplo (Claude Code):**
- Arquivos CLAUDE.md ingenuamente colocados no contexto antecipadamente
- Primitivas (glob, grep) permitem navegação do ambiente e retrieval just-in-time
- Efetivamente evita problemas de indexação obsoleta e árvores de sintaxe complexas

**Aplicações:** Legal e finanças (conteúdo menos dinâmico)

**Tendência futura:** Conforme modelos melhoram, design agêntico tende a deixar modelos inteligentes agirem inteligentemente, com progressivamente menos curadoria humana.

---

## Tarefas de Longo Prazo

### Desafio
Tarefas que abrangem de dezenas de minutos a múltiplas horas de trabalho contínuo (migrações de codebase, projetos de pesquisa abrangentes), onde contagem de tokens excede janela de contexto do LLM.

### Por Que Não Apenas Esperar Janelas Maiores?
Janelas de contexto de todos os tamanhos provavelmente estarão sujeitas a:
- Poluição de contexto
- Preocupações de relevância de informação

Pelo menos para situações onde performance máxima do agente é desejada.

---

### Técnica 1: Compaction (Compactação)

**O que é:**
- Pegar conversação próxima ao limite da janela de contexto
- Resumir seus conteúdos
- Reiniciar nova janela de contexto com o resumo

**Objetivo:** Destilar conteúdos da janela de contexto de maneira high-fidelity, permitindo agente continuar com degradação mínima de performance.

**Exemplo (Claude Code):**
1. Passar histórico de mensagens ao modelo para resumir e comprimir detalhes críticos
2. Modelo preserva: decisões arquiteturais, bugs não resolvidos, detalhes de implementação
3. Modelo descarta: tool outputs redundantes ou mensagens
4. Agente continua com contexto comprimido + 5 arquivos acessados mais recentemente

**Arte da compactação:**
Seleção do que manter vs. descartar. Compactação excessivamente agressiva pode resultar em perda de contexto sutil mas crítico cuja importância só se torna aparente depois.

**Recomendações:**
1. Tune cuidadosamente seu prompt em traces complexos de agente
2. Começar maximizando recall (capturar toda informação relevante)
3. Iterar para melhorar precision (eliminando conteúdo supérfluo)

**Low-hanging fruit:** Tool result clearing - uma vez que ferramenta foi chamada profundamente no histórico, por que agente precisaria ver resultado bruto novamente?

---

### Técnica 2: Structured Note-Taking (Memória Agêntica)

**O que é:**
Agente regularmente escreve notas persistidas em memória fora da janela de contexto. Notas são puxadas de volta quando necessário.

**Benefícios:**
- Memória persistente com overhead mínimo
- Permite rastrear progresso através de tarefas complexas
- Mantém contexto crítico e dependências

**Exemplos:**
- Claude Code criando to-do list
- Agente customizado mantendo arquivo NOTES.md

**Caso real - Claude jogando Pokémon:**
- Mantém contagens precisas através de milhares de passos de jogo
- Rastreia objetivos: "nos últimos 1.234 passos treinando Pokémon na Rota 1, Pikachu ganhou 8 níveis em direção à meta de 10"
- Desenvolve mapas de regiões exploradas
- Lembra achievements-chave desbloqueados
- Mantém notas estratégicas de combate

**Após resets de contexto:**
- Agente lê suas próprias notas
- Continua sequências de treinamento multi-hora
- Explora dungeons
- Coerência através de passos de sumarização

**Memory tool (Beta):**
Ferramenta de memória na Claude Developer Platform facilita armazenar e consultar informações fora da janela de contexto através de sistema baseado em arquivos.

---

### Técnica 3: Sub-Agent Architectures

**O que é:**
Ao invés de um agente tentando manter estado através de projeto inteiro, sub-agentes especializados tratam tarefas focadas com janelas de contexto limpas.

**Estrutura:**
- **Agente principal:** Coordena com plano high-level
- **Subagentes:** Performam trabalho técnico profundo ou usam ferramentas para encontrar informação relevante

**Cada subagente:**
- Pode explorar extensivamente (dezenas de milhares de tokens ou mais)
- Retorna apenas resumo condensado e destilado (geralmente 1.000-2.000 tokens)

**Benefícios:**
- Separação clara de preocupações
- Contexto de busca detalhado permanece isolado dentro de sub-agentes
- Agente principal foca em sintetizar e analisar resultados

**Caso real:**
Sistema de pesquisa multi-agente da Anthropic mostrou melhoria substancial sobre sistemas single-agent em tarefas complexas de pesquisa.

---

## Escolha de Técnica

**Compaction:**
- Mantém fluxo conversacional
- Ideal para tarefas requerendo extensivo back-and-forth

**Note-taking:**
- Excelente para desenvolvimento iterativo com milestones claros
- Tarefas que naturalmente se dividem em fases

**Multi-agent architectures:**
- Lidam com pesquisa e análise complexas
- Onde exploração paralela paga dividendos
- Tarefas que se beneficiam de especialização

---

## Melhores Práticas

### Princípios Core (Anthropic)

**1. Mantenha simplicidade no design do agente**
- Comece simples
- Adicione complexidade apenas quando demonstravelmente melhora resultados

**2. Priorize transparência**
- Mostre explicitamente passos de planejamento do agente
- Facilita debug e confiança

**3. Craft cuidadosamente Agent-Computer Interface (ACI)**
- Documentação completa de ferramentas
- Testes extensivos
- Invista tanto esforço em ACI quanto em HCI (Human-Computer Interface)

---

### Tool Engineering (Prompt Engineering suas Ferramentas)

**Formatos de ferramenta:**
Mesma ação pode ser especificada de várias formas. Alguns formatos são muito mais difíceis para LLM escrever que outros.

**Exemplo - Edit de arquivo:**
- ❌ **Diff:** Requer saber quantas linhas estão mudando no chunk header antes de escrever novo código
- ✅ **Rewrite completo:** Mais fácil para o modelo

**Exemplo - Output estruturado:**
- ❌ **JSON:** Requer escaping extra de newlines e quotes
- ✅ **Markdown:** Mais próximo do texto natural

**Recomendações:**

**1. Dê tokens suficientes para "pensar"**
Antes que o modelo se escreva em um canto.

**2. Mantenha formato próximo do que modelo viu naturalmente**
Texto na internet durante treinamento.

**3. Elimine overhead de formatação**
- Manter contagem precisa de milhares de linhas
- String-escaping de código

**4. Ponha-se nos sapatos do modelo**
É óbvio como usar essa ferramenta baseado na descrição e parâmetros? Se não, também não será para o modelo.

**5. Boa definição de ferramenta inclui:**
- Uso exemplar
- Edge cases
- Requisitos de formato de input
- Limites claros em relação a outras ferramentas

**6. Pense nisso como escrever ótima docstring**
Para desenvolvedor júnior no seu time. Especialmente importante ao usar muitas ferramentas similares.

**7. Teste como modelo usa suas ferramentas**
Execute muitos inputs de exemplo no workbench para ver quais erros o modelo comete. Itere.

**8. Poka-yoke suas ferramentas**
Mude argumentos para tornar mais difícil cometer erros.

**Exemplo real (SWE-bench):**
- **Problema:** Modelo fazia erros com ferramentas usando relative filepaths após sair do root directory
- **Solução:** Mudança para sempre requerer absolute filepaths
- **Resultado:** Modelo usou método perfeitamente

**Investimento:** Time da Anthropic passou mais tempo otimizando ferramentas do que o prompt geral ao construir agente para SWE-bench.

---

### Frameworks

**Disponíveis:**
- Claude Agent SDK
- Strands Agents SDK (AWS)
- Rivet (GUI drag-and-drop LLM workflow builder)
- Vellum (GUI para construir e testar workflows complexos)

**Vantagens:**
- Facilitam começar
- Simplificam tarefas low-level padrão (chamar LLMs, definir e parsear ferramentas, encadear chamadas)

**Desvantagens:**
- Criam camadas extras de abstração
- Podem obscurecer prompts e respostas subjacentes (dificulta debug)
- Tentação de adicionar complexidade quando setup mais simples seria suficiente

**Recomendação Anthropic:**
1. **Comece usando APIs de LLM diretamente** - muitos padrões podem ser implementados em poucas linhas de código
2. **Se usar framework:** Certifique-se de entender código subjacente
3. **Erro comum:** Suposições incorretas sobre o que está "under the hood"

---

### Guia de Implementação

**1. Comece simples**
- Prompts simples primeiro
- Otimize com avaliação abrangente
- Adicione sistemas agênticos multi-step apenas quando soluções mais simples falham

**2. Meça performance**
- Itere em implementações
- Adicione complexidade apenas quando demonstravelmente melhora resultados

**3. Para agentes, sempre:**
- Testes extensivos em ambientes sandbox
- Guardrails apropriados
- Condições de parada claras (ex: número máximo de iterações)

**4. Trate contexto como recurso finito**
- Curadoria cuidadosa de tokens
- Fase de curadoria acontece cada vez que decide o que passar ao modelo
- Contexto é iterativo (vs. tarefa discreta de escrever prompt)

---

## Aplicações em Produção

### A. Customer Support (Atendimento ao Cliente)

**Por que funciona bem:**
- Interfaces de chatbot familiares + capacidades aprimoradas via integração de ferramentas
- Interações de suporte seguem naturalmente fluxo conversacional
- Requer acesso a informações externas e ações
- Ferramentas podem ser integradas: dados de cliente, histórico de pedidos, artigos de knowledge base
- Ações (reembolsos, atualizar tickets) tratadas programaticamente
- Sucesso claramente mensurável através de resoluções definidas pelo usuário

**Validação comercial:**
Várias empresas demonstraram viabilidade através de modelos de pricing baseado em uso (cobram apenas por resoluções bem-sucedidas), mostrando confiança na efetividade dos agentes.

---

### B. Coding Agents (Agentes de Codificação)

**Por que funciona bem:**
- Soluções de código são verificáveis através de testes automatizados
- Agentes podem iterar em soluções usando resultados de testes como feedback
- Espaço de problema bem-definido e estruturado
- Qualidade de output objetivamente mensurável

**Progresso:**
Evolução de code completion → resolução autônoma de problemas.

**Caso real (Anthropic):**
Agentes agora resolvem issues reais do GitHub no benchmark SWE-bench Verified baseado apenas na descrição do pull request.

**Importante:**
Embora testes automatizados ajudem a verificar funcionalidade, revisão humana permanece crucial para assegurar que soluções alinham com requisitos mais amplos do sistema.

---

## Resumo Executivo

### Mensagem Central
Sucesso com LLMs não é sobre construir sistema mais sofisticado. É sobre construir o sistema **certo** para suas necessidades.

### Hierarquia de Complexidade
1. **Prompts simples** → Comece aqui
2. **Otimização com avaliação abrangente** → Melhore incrementalmente
3. **Sistemas agênticos multi-step** → Apenas quando soluções mais simples falham

### Conforme Modelos Melhoram
- Challenge de manter coerência através de interações estendidas permanecerá central
- Modelos mais inteligentes requerem menos engenharia prescritiva
- Agentes podem operar com mais autonomia
- Mas tratar contexto como recurso precioso e finito sempre será essencial

### Melhor Conselho
**"Faça a coisa mais simples que funciona"** - provavelmente permanecerá melhor conselho conforme campo avança rapidamente.

---

## Recursos Adicionais

### Documentação Oficial Anthropic
- Developer docs
- Memory and context management cookbook
- Prompt engineering strategies

### Conceitos Relacionados
- Model Context Protocol (MCP)
- Tool result clearing
- Progressive disclosure
- Agent-Computer Interface (ACI)

---

*Referências baseadas em:*
- "Building effective agents" (Anthropic, Dec 2024)
- "Effective context engineering for AI agents" (Anthropic, Sep 2025)
- "A practical guide to building agents" (Anthropic)
