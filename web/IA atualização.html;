<!DOCTYPE html>
<html lang="pt-BR" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>IA descomplicada: o guia para leigos - edição ultra</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800&family=JetBrains+Mono:wght@400;700&display=swap" rel="stylesheet">
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                        mono: ['JetBrains Mono', 'monospace'],
                    },
                    colors: {
                        bg: '#0f172a', // Slate 900
                        sidebar: '#020617', // Slate 950
                        accent: '#38bdf8', // Sky 400
                        text: '#e2e8f0', // Slate 200
                        muted: '#94a3b8', // Slate 400
                        border: '#1e293b', // Slate 800
                        // Cores do ChatGPT Dark Mode
                        'chatgpt-main': '#343541',
                        'chatgpt-sidebar': '#202123',
                        'chatgpt-ai-message': '#444654',
                        'chatgpt-input-bg': '#40414f',
                    }
                }
            }
        }
    </script>
    <style>
        /* Estilos de Documentação (Prose) - Mantidos para o Guia */
        .prose { max-width: none; }
        .prose h2 { margin-top: 4rem; margin-bottom: 1.5rem; color: white; font-weight: 800; font-size: 2.25rem; letter-spacing: -0.025em; border-bottom: 1px solid #1e293b; padding-bottom: 0.75rem; }
        .prose h3 { margin-top: 2.5rem; margin-bottom: 1rem; color: #38bdf8; font-weight: 600; font-size: 1.5rem; }
        .prose p { margin-bottom: 1.5rem; line-height: 1.8; color: #cbd5e1; font-size: 1.1rem; }
        .prose strong { color: white; font-weight: 700; }
        .prose ul, .prose ol { margin-bottom: 1.5rem; padding-left: 1.5rem; }
        .prose ul { list-style-type: disc; }
        .prose ol { list-style-type: decimal; }
        .prose li { margin-bottom: 0.75rem; color: #cbd5e1; }
        .callout { background: rgba(56, 189, 248, 0.05); border-left: 4px solid #38bdf8; padding: 1.5rem; margin: 2rem 0; border-radius: 0 0.5rem 0.5rem 0; color: #e2e8f0; }
        .analogy-box { background: #1e293b; border: 1px dashed #475569; padding: 1.5rem; border-radius: 0.75rem; margin: 2rem 0; }
        .analogy-title { text-transform: uppercase; font-size: 0.75rem; font-weight: 700; letter-spacing: 0.05em; color: #94a3b8; margin-bottom: 0.5rem; display: block; }
        .page-layout { display: flex; min-height: 100vh; }
        aside { flex: 0 0 18rem; top: 0; position: sticky; height: 100vh; }
        main { flex: 1; min-width: 0; }
        @media (max-width: 767px) {
            .page-layout { flex-direction: column; }
            aside { position: fixed; height: 100%; width: 100%; z-index: 50; transform: translateX(-100%); }
            aside.open { transform: translateX(0); }
            main { padding-top: 5rem !important; }
        }

        /* -------------------------------------------------------------------------------- */
        /* NOVOS ESTILOS: UI CHATGPT */
        /* -------------------------------------------------------------------------------- */

        #chat-window {
            transition: transform 0.3s ease-out;
            bottom: 6rem; 
            background-color: theme('colors.chatgpt-main');
            color: #d1d5db;
        }

        /* Estilos das mensagens da IA (faixa cinza) */
        .message-ai-bg {
            background-color: theme('colors.chatgpt-ai-message'); 
        }

        /* Container de Input - flutuante e escuro */
        .chat-input-area {
            background-color: theme('colors.chatgpt-input-bg'); 
            border: 1px solid rgba(255, 255, 255, 0.1);
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }
        
        /* Área de Input - remover focus ring azul */
        #chat-input {
             /* Estilos de padding para acomodar o botão de envio */
             padding-top: 14px !important; 
             padding-bottom: 14px !important;
        }
        #chat-input:focus {
            outline: none !important;
            box-shadow: none !important;
            border-color: transparent !important;
            ring: none !important;
        }

        /* Ajuste do wrapper de conteúdo da mensagem para a janela pequena */
        .message-content-wrapper {
            max-width: 95%; /* Adaptação para a largura de 96 */
        }
        
        /* Botão de Envio (ATUALIZADO PARA AZUL E SETA BRANCA) */
        .send-button-style {
            transition: all 0.2s ease;
            background-color: #3b82f6; /* Azul Primário */
            color: #ffffff; /* Seta branca */
        }
        .send-button-style:hover {
             background-color: #2563eb; /* Azul mais escuro no hover */
        }
        .send-button-style:disabled {
            background-color: theme('colors.chatgpt-input-bg') !important; /* Fundo do input */
            color: #8e8e8e !important; /* Ícone cinza claro (desativado) */
            cursor: default;
        }

    </style>
</head>
<body class="bg-bg text-text font-sans antialiased">

    <!-- Mobile Header -->
    <div class="md:hidden fixed top-0 w-full bg-sidebar border-b border-border z-50 px-4 py-3 flex justify-between items-center">
        <span class="font-bold text-accent tracking-tighter">IA.ULTRA</span>
        <button id="mobile-menu-btn" onclick="toggleSidebar()" class="text-text p-2 rounded-md hover:bg-slate-800 transition"><i class="fas fa-bars"></i></button>
    </div>

    <div class="page-layout">
        <!-- Sidebar Navigation (Table of Contents) -->
        <aside id="sidebar" class="bg-sidebar border-r border-border transition-transform duration-300 overflow-y-auto hidden md:block">
            <div class="p-6">
                <h1 class="text-2xl font-extrabold text-white tracking-tighter mb-2">IA<span class="text-accent">.PARA LEIGOS</span></h1>
                <p class="text-xs text-muted uppercase tracking-widest font-semibold">Guia essencial aprofundado</p>
            </div>
            
            <nav class="px-4 space-y-1 pb-10">
                <a href="#intro" class="block px-3 py-2 text-sm font-medium text-white bg-slate-800 rounded-md">Início</a>
                
                <div class="pt-6 pb-2 text-xs font-bold text-muted uppercase tracking-wider px-3">O motor da conversa</div>
                <a href="#llm-motor" class="block px-3 py-2 text-sm text-gray-300 hover:text-white hover:bg-slate-800 rounded-md transition">1. LLMs: previsão e contexto</a>
                
                <div class="pt-6 pb-2 text-xs font-bold text-muted uppercase tracking-wider px-3">Fundamentos</div>
                <a href="#ani-agi" class="block px-3 py-2 text-sm text-gray-300 hover:text-white hover:bg-slate-800 rounded-md transition">2. Especialista vs. gênio</a>
                <a href="#deep-learning" class="block px-3 py-2 text-sm text-gray-300 hover:text-white hover:bg-slate-800 rounded-md transition">3. O funil de filtros</a>
                <a href="#vetores" class="block px-3 py-2 text-sm text-gray-300 hover:text-white hover:bg-slate-800 rounded-md transition">4. O mapa de significado</a>

                <div class="pt-6 pb-2 text-xs font-bold text-muted uppercase tracking-wider px-3">Desafios e aplicações</div>
                <a href="#alucinacao" class="block px-3 py-2 text-sm text-gray-300 hover:text-white hover:bg-slate-800 rounded-md transition">5. O mentiroso confiante</a>
                <a href="#rag" class="block px-3 py-2 text-sm text-gray-300 hover:text-white hover:bg-slate-800 rounded-md transition">6. A prova de consulta</a>
                <a href="#finetuning" class="block px-3 py-2 text-sm text-gray-300 hover:text-white hover:bg-slate-800 rounded-md transition">7. Mudança de estilo</a>
                <a href="#multimodalidade" class="block px-3 py-2 text-sm text-gray-300 hover:text-white hover:bg-slate-800 rounded-md transition">8. Visão e linguagem</a>
            </nav>
        </aside>

        <!-- Main Content Area -->
        <main class="flex-1 p-8 md:p-16 max-w-5xl mx-auto prose prose-invert">
            
            <!-- Intro Section -->
            <section id="intro" class="mb-20 scroll-mt-24">
                <h1 class="text-5xl md:text-7xl font-extrabold text-white tracking-tight mb-8">
                    <i class="fas fa-microchip text-accent mr-4"></i>Documentação da IA para leigos
                </h1>
                <p class="text-2xl text-gray-300 leading-relaxed font-light">
                    Esqueça o *hype* e o marketing. Este é o guia técnico-funcional escrito para quem não é engenheiro, mas precisa de entender como a máquina pensa. Vamos abrir a "caixa preta" da Inteligência Artificial e explicar o motor, as peças e o combustível.
                </p>
            </section>

            <hr class="border-border my-12 opacity-50">

            <!-- MÓDULO 1: LLM -->
            <section id="llm-motor" class="scroll-mt-24">
                <span class="text-accent font-mono text-sm font-bold tracking-widest uppercase border border-accent px-2 py-1 rounded">Módulo 01</span>
                <h2>LLMs: o motor da revolução</h2>
                
                <div class="analogy-box">
                    <span class="analogy-title">A Analogia Central</span>
                    <h3 class="mt-0 text-white">O Autocompletar Anabolizado</h3>
                    <p class="mb-0">Imagine o teclado do seu telemóvel. Quando escreve "Bom", ele sugere "dia". O ChatGPT ou o Gemini são, na sua essência, versões trilionárias desse teclado. Eles não "sabem" a resposta; eles calculam qual a palavra que tem a maior probabilidade estatística de vir a seguir.</p>
                </div>

                <h3>1.1 O que é um LLM?</h3>
                <p>
                    LLM significa <strong>Large Language Model</strong> (Grande Modelo de Linguagem). É um ficheiro de computador gigante (pense em gigabytes de números) que foi "treinado" ao ler uma parte significativa da internet.
                </p>
                <p>
                    Ao ler biliões de frases, o modelo aprendeu a estrutura da linguagem humana. Ele não aprendeu factos da mesma forma que nós (ele não sabe que o céu é azul porque o viu), ele aprendeu que a palavra "azul" aparece frequentemente depois das palavras "o céu é".
                </p>

                <h3>1.2 Como funciona a "magia"? (Previsão de Tokens)</h3>
                <p>
                    O computador não lê palavras inteiras. Ele quebra o texto em pedaços chamados <strong>Tokens</strong>.
                </p>
                <ul class="list-disc">
                    <li>A palavra "casa" pode ser 1 token.</li>
                    <li>A palavra "implementação" pode ser 3 tokens: "im", "ple", "mentação".</li>
                </ul>
                <p>
                    O processo de geração de resposta é uma <strong>previsão probabilística</strong>. Quando faz uma pergunta, o modelo analisa os seus tokens e calcula: <em>"Dado este contexto, qual é o token com maior probabilidade de vir a seguir?"</em>. Ele escolhe um, adiciona-o à frase, e repete o cálculo para o próximo. É por isso que a IA "escreve" palavra por palavra no ecrã.
                </p>
                <div class="callout">
                    <strong>Conceito Chave: Temperatura.</strong> Este é o "botão de criatividade". Se a temperatura for 0, a IA escolhe sempre a palavra mais provável (ficando robótica e repetitiva). Se a temperatura for alta (perto de 1), ela arrisca palavras menos prováveis, tornando-se mais "criativa" (e propensa a erros).
                </div>
                

                <h3>1.3 A Janela de Contexto (A Memória RAM)</h3>
                <p>
                    A IA não tem memória infinita. Ela tem uma <strong>Janela de Contexto</strong>. Imagine uma mesa de trabalho: só pode colocar um certo número de folhas de papel nela. Se a mesa encher e quiser adicionar uma folha nova, uma antiga tem de cair.
                </p>
                <p>
                    Tudo o que diz à IA, e tudo o que ela responde, tem de caber nesta "mesa". Se a conversa for muito longa, o início "cai da mesa" e a IA esquece o seu nome ou a primeira instrução que deu. Modelos modernos têm "mesas" gigantescas (milhões de tokens), mas o limite existe sempre.
                </p>
            </section>


            <!-- MÓDULO 2: ANI vs AGI -->
            <section id="ani-agi" class="scroll-mt-24">
                <span class="text-accent font-mono text-sm font-bold tracking-widest uppercase border border-accent px-2 py-1 rounded">Módulo 02</span>
                <h2>Especialista vs. gênio (ANI vs. AGI)</h2>
                
                <div class="analogy-box">
                    <span class="analogy-title">A Analogia</span>
                    <h3 class="mt-0 text-white">A Calculadora vs. O Cérebro</h3>
                    <p class="mb-0">Uma calculadora faz contas mais rápido que qualquer humano (ANI), mas não sabe escrever um poema. Um humano (AGI) faz contas devagar, mas pode aprender a escrever poemas, cozinhar e andar de bicicleta.</p>
                </div>

                <h3>2.1 ANI: A realidade atual</h3>
                <p>
                    Toda a IA que existe hoje é <strong>ANI (Artificial Narrow Intelligence)</strong>, ou Inteligência Estreita. Ela é "estreita" porque é focada. Um modelo treinado para diagnosticar cancro não consegue jogar xadrez. O ChatGPT, embora pareça saber tudo, é apenas um especialista em *linguagem*. Ele não "sabe" física, ele sabe *falar sobre* física.
                </p>

                <h3>2.2 AGI: O sonho distante</h3>
                <p>
                    A <strong>AGI (Artificial General Intelligence)</strong> seria uma máquina com a flexibilidade cognitiva de um humano. Poderia aprender qualquer tarefa nova sem precisar de ser re-treinada do zero. Muitos especialistas vendem a ideia de que a AGI está "ao virar da esquina" para aumentar o investimento, mas a verdade técnica é que os LLMs atuais (Módulo 1) podem não ser o caminho para lá chegar, pois falta-lhes raciocínio lógico real e compreensão do mundo físico.
                </p>
                
            </section>

            <!-- MÓDULO 3: Deep Learning -->
            <section id="deep-learning" class="scroll-mt-24">
                <span class="text-accent font-mono text-sm font-bold tracking-widest uppercase border border-accent px-2 py-1 rounded">Módulo 03</span>
                <h2>Deep learning: o funil de filtros</h2>
                
                <div class="analogy-box">
                    <span class="analogy-title">A Analogia</span>
                    <h3 class="mt-0 text-white">Quem é Quem? (O Jogo)</h3>
                    <p class="mb-0">Imagine um jogo onde tenta adivinhar o animal numa foto fazendo perguntas de sim/não em sequência: "Tem pelo?" -> "Tem orelhas pontudas?" -> "Miau?". Cada pergunta é uma camada da rede neural.</p>
                </div>

                <h3>3.1 Redes Neurais Profundas</h3>
                <p>
                    O "Deep" em Deep Learning refere-se à profundidade das camadas de uma <strong>Rede Neural</strong>. Ao contrário do software tradicional, onde um humano escreve as regras (`se x então y`), no Deep Learning a máquina descobre as regras sozinha.
                </p>
                <p>
                    Imagine uma pilha de filtros transparentes.
                </p>
                <ul class="list-disc">
                    <li><strong>Camada 1:</strong> Olha para os pixels e encontra apenas linhas retas e curvas.</li>
                    <li><strong>Camada 10:</strong> Junta essas linhas e encontra formas (círculos, quadrados).</li>
                    <li><strong>Camada 50:</strong> Junta os formas e encontra componentes (um olho, um pneu).</li>
                    <li><strong>Camada 100:</strong> Junta os componentes e identifica "Gato" ou "Carro".</li>
                </ul>
                <p>
                    É esta capacidade de construir conhecimento complexo a partir de blocos simples, camada por camada, que permitiu à IA começar a "ver" e "ler".
                </p>
            </section>

            <!-- MÓDULO 4: Vetores -->
            <section id="vetores" class="scroll-mt-24">
                <span class="text-accent font-mono text-sm font-bold tracking-widest uppercase border border-accent px-2 py-1 rounded">Módulo 04</span>
                <h2>Vetores: o mapa de significado</h2>
                
                <div class="analogy-box">
                    <span class="analogy-title">A Analogia</span>
                    <h3 class="mt-0 text-white">O Supermercado das Palavras</h3>
                    <p class="mb-0">Num supermercado, a "Maçã" está na prateleira ao lado da "Pera", mas longe do "Detergente". A IA organiza todas as palavras do mundo num "supermercado gigante" (espaço vetorial). Ela sabe o que as palavras significam pela distância física entre elas nas prateleiras.</p>
                </div>

                <h3>4.1 Traduzindo Palavras para Números</h3>
                <p>
                    Computadores não entendem "amor" ou "ódio". Eles só entendem números. Para a IA funcionar, precisamos de converter palavras em listas de números chamadas <strong>Vetores</strong> (ou Embeddings).
                </p>
                <p>
                    A mágica acontece no <strong>Espaço Vetorial</strong>. É um mapa 3D (na verdade, com milhares de dimensões) onde cada conceito tem uma coordenada GPS.
                </p>
                <ul class="list-disc">
                    <li>A coordenada de "Rei" está matematicamente próxima de "Rainha".</li>
                    <li>Se fizermos a conta `Coordenada(Rei) - Coordenada(Homem) + Coordenada(Mulher)`, o resultado cai exatamente na coordenada de `Rainha`.</li>
                </ul>
                <p>
                    É assim que a IA "entende" o significado. Ela não lê; ela calcula distâncias. Se você pesquisar "animal doméstico", ela encontra "gato" não porque as palavras são parecidas, mas porque os seus vetores moram no mesmo bairro matemático.
                </p>
                
            </section>

            <!-- MÓDULO 5: Alucinação -->
            <section id="alucinacao" class="scroll-mt-24">
                <span class="text-accent font-mono text-sm font-bold tracking-widest uppercase border border-accent px-2 py-1 rounded">Módulo 05</span>
                <h2>Alucinação: o mentiroso confiante</h2>
                
                <div class="analogy-box">
                    <span class="analogy-title">A Analogia</span>
                    <h3 class="mt-0 text-white">O Aluno do Fundo da Sala</h3>
                    <p class="mb-0">Imagine um aluno que não estudou para a prova, mas escreve muito bem. Quando lhe fazem uma pergunta que ele não sabe, ele inventa uma resposta eloquente, cheia de palavras caras, que *parece* correta, mas é pura invenção. Isso é a IA a alucinar.</p>
                </div>

                <h3>5.1 Por que a IA mente?</h3>
                <p>
                    Lembre-se do Módulo 1: a função da IA é prever a próxima palavra para completar um padrão. A função dela <strong>não é</strong> dizer a verdade.
                </p>
                <p>
                    Se você perguntar "Quem foi o primeiro homem a pisar em Marte?", o padrão linguístico de perguntas sobre "pisar em..." leva a IA a querer responder "Neil Armstrong", porque essa é a associação estatística mais forte com "primeiro homem a pisar".
                </p>
                <p>
                    A IA não tem um conceito de "facto" vs. "ficção". Ela só tem "provável" vs. "improvável". Se a mentira for linguisticamente provável (soar bem), ela vai dizê-la com total confiança. É por isso que o humano nunca pode sair do ciclo de verificação.
                </p>
            </section>

            <!-- MÓDULO 6: RAG -->
            <section id="rag" class="scroll-mt-24">
                <span class="text-accent font-mono text-sm font-bold tracking-widest uppercase border border-accent px-2 py-1 rounded">Módulo 06</span>
                <h2>RAG: a prova de consulta</h2>
                
                <div class="analogy-box">
                    <span class="analogy-title">A Analogia</span>
                    <h3 class="mt-0 text-white">O Assistente Jurídico</h3>
                    <p class="mb-0">Um advogado (o LLM) sabe falar muito bem, mas não decorou todas as leis novas que saíram ontem. O RAG é o assistente que corre para a biblioteca, pega no livro de leis exato (a sua base de dados) e coloca-o na frente do advogado dizendo: "Use isto para responder".</p>
                </div>

                <h3>6.1 Retrieval-Augmented Generation</h3>
                <p>
                    Como resolvemos a alucinação e o facto de a IA não saber os dados da sua empresa? Com <strong>RAG</strong>.
                </p>
                <p>
                    O processo tem três passos simples:
                </p>
                <ol class="list-decimal">
                    <li><strong>Pergunta:</strong> O usuário faz uma pergunta.</li>
                    <li><strong>Busca (Retrieval):</strong> O sistema não manda a pergunta logo para a IA. Primeiro, ele usa um sistema de busca (baseado em Vetores, Módulo 4) para vasculhar os seus documentos PDF, Excel ou emails e encontrar os parágrafos que contêm a resposta.</li>
                    <li><strong>Geração (Generation):</strong> O sistema pega nesses parágrafos encontrados e envia-os para a IA com uma ordem: *"Usando APENAS estas informações que eu encontrei, responde à pergunta do usuário"*.</li>
                </ol>
                <p>
                    Isso "terraplana" a IA. Ela deixa de criar ficção e passa a resumir factos que você lhe forneceu.
                </p>
                [Image of Retrieval-Augmented Generation (RAG) process]
            </section>

            <!-- MÓDULO 7: Fine-Tuning -->
            <section id="finetuning" class="scroll-mt-24">
                <span class="text-accent font-mono text-sm font-bold tracking-widest uppercase border border-accent px-2 py-1 rounded">Módulo 07</span>
                <h2>Fine-tuning: mudança de estilo</h2>
                
                <div class="analogy-box">
                    <span class="analogy-title">A Analogia</span>
                    <h3 class="mt-0 text-white">A Escola de Atores</h3>
                    <p class="mb-0">O RAG dá ao ator o *guião* (o que dizer). O Fine-Tuning manda o ator para uma escola de teatro para aprender *como* falar com um sotaque específico.</p>
                </div>

                <h3>7.1 Quando usar?</h3>
                <p>
                    Há uma confusão comum no mercado. As pessoas acham que precisam "treinar a IA" (Fine-tuning) para ela aprender os dados da empresa. <strong>Isso geralmente está errado.</strong> Para dados, usa-se RAG.
                </p>
                <p>
                    O Fine-tuning serve para alterar o <strong>comportamento</strong>.
                </p>
                <ul class="list-disc">
                    <li>Quer que a IA responda sempre em formato JSON? Fine-tuning.</li>
                    <li>Quer que a IA fale como um pirata ou como um médico do século 19? Fine-tuning.</li>
                    <li>Quer que a IA seja mais concisa e pare de pedir desculpa? Fine-tuning.</li>
                </ul>
                <p>
                    É um processo caro e técnico onde ajustamos os "pesos" do cérebro da IA. Use apenas quando o RAG não for suficiente para acertar o "tom de voz".
                </p>
            </section>

            <!-- MÓDULO 8: Multimodalidade -->
            <section id="multimodalidade" class="scroll-mt-24 mb-20">
                <span class="text-accent font-mono text-sm font-bold tracking-widest uppercase border border-accent px-2 py-1 rounded">Módulo 08</span>
                <h2>Multimodalidade: visão e linguagem</h2>
                
                <div class="analogy-box">
                    <span class="analogy-title">A Analogia</span>
                    <h3 class="mt-0 text-white">Deixando de ser Cego e Surdo</h3>
                    <p class="mb-0">As IAs antigas viviam num mundo de texto, como um terminal de computador dos anos 80. As IAs multimodais (como o Gemini) ganharam olhos e ouvidos. Elas processam o mundo como nós.</p>
                </div>

                <h3>8.1 Tudo vira Vetor</h3>
                <p>
                    A grande revolução recente foi descobrir que podemos usar a mesma técnica de **Vetores** (Módulo 4) para imagens e som.
                </p>
                <p>
                    A IA transforma uma foto de um gato numa lista de números. Transforma a palavra "gato" numa lista de números. E, surpresa: esses números são compatíveis! Isso permite que a IA "veja" a foto e "escreva" sobre ela, porque no cérebro dela, imagem e texto são a mesma língua matemática.
                </p>
                <p>
                    Isso abre portas para aplicações incríveis: mostrar-lhe a foto de uma peça quebrada e pedir o manual de reparação, ou filmar uma prateleira de supermercado e pedir para identificar produtos em falta.
                </p>
                
            </section>

            <!-- Footer -->
            <footer class="border-t border-border pt-8 pb-20 text-center text-muted text-sm">
                <p>&copy; 2025 IA descomplicada. O guia definitivo.</p>
            </footer>

        </main>
    </div>

    <!-- Floating Chat Button -->
    <button id="chat-toggle-button" onclick="toggleChat()" class="fixed bottom-6 right-6 bg-accent text-sidebar w-14 h-14 rounded-full shadow-lg hover:bg-white transition-all flex items-center justify-center z-50">
        <i class="fas fa-comment-dots text-2xl"></i>
    </button>

    <!-- Chat Window - Estilo ChatGPT -->
    <div id="chat-window" class="fixed right-6 w-96 bg-chatgpt-main border border-slate-700 rounded-xl shadow-2xl z-50 flex flex-col h-[600px] translate-y-[120%] hidden">
        
        <!-- Header Simples -->
        <div class="p-3 border-b border-slate-700 bg-chatgpt-sidebar rounded-t-xl flex justify-between items-center flex-shrink-0">
            <h3 class="font-bold text-white flex items-center"><i class="fas fa-gem mr-2 text-accent"></i>Tutor IA - Guia</h3>
            <button onclick="toggleChat()" class="text-gray-400 hover:text-white p-1 rounded-md hover:bg-slate-700 transition"><i class="fas fa-times"></i></button>
        </div>
        
        <!-- Corpo das Mensagens (Scrollable) -->
        <div id="chat-content" class="flex-1 overflow-y-auto bg-chatgpt-main flex flex-col gap-0 pt-0">
            <!-- As mensagens serão adicionadas aqui por JavaScript -->
        </div>
        
        <!-- Input Area (Estilo ChatGPT) -->
        <div class="p-3 border-t border-slate-700 flex-shrink-0 bg-chatgpt-main">
            <div class="relative flex items-end chat-input-area rounded-xl shadow-xl">
                <textarea
                    id="chat-input"
                    rows="1"
                    placeholder="Pergunte sobre os módulos (LLM, RAG, Vetores...)"
                    class="w-full resize-none bg-transparent text-gray-200 placeholder-gray-400 p-3 pr-12 overflow-hidden"
                    style="min-height: 52px;"
                ></textarea>
                <!-- Botão de Envio (seta para cima) -->
                <button
                    id="send-button"
                    onclick="sendMessage()"
                    class="absolute right-3 bottom-3 p-2 rounded-xl send-button-style"
                    title="Enviar Mensagem"
                    disabled
                >
                    <i class="fas fa-arrow-up w-4 h-4"></i>
                </button>
            </div>
        </div>
    </div>

    <script>
        // UI Elements
        const sidebar = document.getElementById('sidebar');
        const chatWindow = document.getElementById('chat-window');
        const chatContent = document.getElementById('chat-content');
        const chatInput = document.getElementById('chat-input');
        const chatToggleButton = document.getElementById('chat-toggle-button');
        const sendButton = document.getElementById('send-button');

        // Helper function to scroll chat to bottom
        function scrollToBottom(element) {
            element.scrollTop = element.scrollHeight;
        }

        // Toggles Sidebar for mobile view
        function toggleSidebar() {
            sidebar.classList.toggle('open');
        }

        // Toggles Chat Window with smooth transition
        function toggleChat() {
            const isHidden = chatWindow.classList.contains('hidden');
            if (isHidden) {
                chatWindow.classList.remove('hidden');
                setTimeout(() => {
                    chatWindow.classList.remove('translate-y-[120%]');
                    chatToggleButton.style.display = 'none';
                    chatInput.focus();
                    // Adicionar mensagem inicial só se estiver vazio
                    if (chatContent.children.length === 0) {
                         const initialMessage = "Olá Gabriel! Sou o seu Tutor IA e estou aqui para descomplicar este guia. Pergunte-me qualquer coisa sobre LLMs, RAG ou Alucinação!";
                         addMessageToChat(initialMessage, 'model');
                    }
                    scrollToBottom(chatContent);
                }, 10); 
            } else {
                chatWindow.classList.add('translate-y-[120%]');
                chatToggleButton.style.display = 'flex';
                setTimeout(() => chatWindow.classList.add('hidden'), 300);
            }
        }
        
        // Lógica para auto-ajustar textarea e botão de envio
        chatInput.addEventListener('input', () => {
            chatInput.style.height = 'auto';
            chatInput.style.height = Math.min(chatInput.scrollHeight, 150) + 'px'; // Max height limit
            sendButton.disabled = chatInput.value.trim() === '';
        });

        // Adds a message div to the chat content area (Refactored for ChatGPT look)
        function addMessageToChat(text, role) {
            
            const isUser = role === 'user';
            
            // 1. Definições de Estilo e Ícone
            const bgColorClass = isUser ? 'bg-chatgpt-main' : 'message-ai-bg'; // Fundo da faixa
            const iconContent = isUser 
                ? `<div class="bg-blue-600 rounded-full w-6 h-6 flex items-center justify-center text-white"><i class="fas fa-user text-xs"></i></div>`
                : `<div class="bg-purple-600 rounded-lg w-6 h-6 flex items-center justify-center text-white"><i class="fas fa-gem"></i></div>`; 

            // 2. Elementos da Faixa da Mensagem
            const messageContainer = document.createElement('div');
            messageContainer.className = `w-full py-4 ${bgColorClass} flex-shrink-0`; 

            const messageWrapper = document.createElement('div');
            // Estrutura interna para alinhamento (margin auto)
            messageWrapper.className = 'message-content-wrapper mx-auto flex space-x-4 px-4'; 
            
            const iconDiv = document.createElement('div');
            iconDiv.className = 'w-8 h-8 flex-shrink-0 pt-1 flex items-start justify-center'; 
            iconDiv.innerHTML = iconContent;
            
            const textDiv = document.createElement('div');
            // Usando 'prose-sm prose-invert' para formatar markdown em dark mode e texto pequeno
            textDiv.className = 'flex-1 prose prose-sm prose-invert max-w-none text-gray-100 break-words leading-relaxed';
            
            // Formatação básica de texto (simulação de Markdown para negrito e quebras de linha)
            const formattedText = text
                .replace(/\n/g, '<br>')
                .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
            textDiv.innerHTML = formattedText; 

            messageWrapper.appendChild(iconDiv);
            messageWrapper.appendChild(textDiv);
            messageContainer.appendChild(messageWrapper);
            
            chatContent.appendChild(messageContainer);
            
            scrollToBottom(chatContent);
        }

        // Lógica da API
        const apiKey = ""; 
        const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;
        // Inicializa com a primeira mensagem do modelo
        let chatHistory = [{
            role: "model", 
            parts: [{ text: "Olá Gabriel! Sou o seu Tutor IA e estou aqui para descomplicar este guia. Pergunte-me qualquer coisa sobre LLMs, RAG ou Alucinação!" }]
        }]; 

        async function sendMessage() {
            const text = chatInput.value.trim();
            if (!text) return;

            // 1. Mostrar a mensagem do usuário
            addMessageToChat(text, 'user');
            chatInput.value = '';
            chatInput.style.height = 'auto'; 
            sendButton.disabled = true;
            chatHistory.push({ role: "user", parts: [{ text }] });

            // 2. Mostrar o estado de "loading" (spinner no botão de envio)
            const originalButtonContent = sendButton.innerHTML;
            sendButton.innerHTML = '<i class="fas fa-spinner fa-spin w-4 h-4 text-white"></i>'; // Spinner branco
            sendButton.disabled = true;

            const systemInstruction = { parts: [{ text: "Tu és um tutor amigável e didático, especialista no conteúdo desta página (Guia de IA para Leigos). O teu objetivo é explicar os conceitos (LLM, RAG, Vetores, etc.) usando analogias muito simples e linguagem coloquial. Sê conciso. Responde sempre em Português. Dirija-se ao utilizador como Gabriel." }] };

            try {
                const MAX_RETRIES = 5;
                let attempt = 0;
                let responseData = null;

                while (attempt < MAX_RETRIES) {
                    const delay = Math.pow(2, attempt) * 1000;
                    
                    try {
                        const response = await fetch(apiUrl, {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                contents: chatHistory,
                                systemInstruction: systemInstruction
                            })
                        });

                        if (response.ok) {
                            responseData = await response.json();
                            break; 
                        } else if (response.status === 429 || response.status >= 500) {
                            if (attempt < MAX_RETRIES - 1) {
                                await new Promise(resolve => setTimeout(resolve, delay));
                            }
                        } else {
                            responseData = await response.json(); 
                            break;
                        }
                    } catch (error) {
                        if (attempt < MAX_RETRIES - 1) {
                            await new Promise(resolve => setTimeout(resolve, delay));
                        } else {
                            console.error('API call failed after max retries:', error);
                            break;
                        }
                    }
                    attempt++;
                }
                
                // Processar a resposta
                let modelText = "Desculpe, Gabriel. Houve um erro na comunicação com a IA.";
                if (responseData) {
                    const candidate = responseData.candidates?.[0];
                    const text = candidate?.content?.parts?.[0]?.text;

                    if (text) {
                        modelText = text;
                    }
                }

                addMessageToChat(modelText, 'model');
                chatHistory.push({ role: "model", parts: [{ text: modelText }] });


            } catch (e) {
                console.error("Erro inesperado no chat:", e);
                addMessageToChat("Ocorreu um erro interno. Verifique a consola.", 'model');
            } finally {
                // Resetar o botão de envio
                sendButton.innerHTML = originalButtonContent;
                sendButton.disabled = chatInput.value.trim() === '';
                chatInput.focus();
            }
        }
    </script>

</body>
</html>
